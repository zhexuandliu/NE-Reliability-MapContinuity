{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import CIFAR10, DTD\n",
    "import timm\n",
    "import detectors\n",
    "\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Image preprocessing modules ###########\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n",
    "                         std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404])\n",
    "    # inherited from https://github.com/kaidic/LDAM-DRW/blob/master/cifar_train.py\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_DTD = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    # inherited from https://github.com/OliverXUZY/FM_weights/blob/124360fdfb2027319993a2be48caf7cb7a0887aa/src/dataset.py#L56\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: 5000, 9: 5000, 4: 5000, 1: 5000, 2: 5000, 7: 5000, 8: 5000, 3: 5000, 5: 5000, 0: 5000}\n",
      "10\n",
      "{3: 1000, 8: 1000, 0: 1000, 6: 1000, 1: 1000, 9: 1000, 5: 1000, 7: 1000, 4: 1000, 2: 1000}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "########### dataset loading ###########\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "# CIFAR-10 dataset \n",
    "train_dataset = CIFAR10(root='data/', train=True, transform=transform_train, download=False)\n",
    "test_dataset = CIFAR10(root='data/', train=False, transform=transform_test, download=False)\n",
    "\n",
    "# DTD dataset \n",
    "DTD_dataset = DTD(root='data/', transform=transform_DTD, download=False)\n",
    "\n",
    "print(dict(Counter(train_dataset.targets)))\n",
    "print(len(dict(Counter(train_dataset.targets))))\n",
    "\n",
    "print(dict(Counter(test_dataset.targets)))\n",
    "print(len(dict(Counter(test_dataset.targets))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Pretrained model ###########\n",
    "# https://huggingface.co/edadaltocg/resnet18_cifar10\n",
    "model = timm.create_model(\"resnet18_cifar10\", pretrained=True)\n",
    "# remove the last fully-connected layer, output dimension: 512\n",
    "new_model = torch.nn.Sequential(OrderedDict([*(list(model.named_children())[:-1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### training dataset feature, logits, and pics ##########\n",
    "\n",
    "model.eval()\n",
    "new_model.eval()\n",
    "\n",
    "logits_mat = torch.empty((len(train_dataset), 10))\n",
    "features_mat = torch.empty((len(train_dataset), 512))\n",
    "labels_mat = torch.empty((len(train_dataset), 1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(train_dataset)):\n",
    "        x, y = train_dataset[i]\n",
    "        x = x.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        logits = model(x)\n",
    "        logits_mat[i] = logits.squeeze(0)\n",
    "\n",
    "        features = new_model(x)\n",
    "        features_mat[i] = features.squeeze(0)\n",
    "\n",
    "        labels_mat[i] = y\n",
    "\n",
    "probs_mat = softmax(logits_mat, dim=1)\n",
    "features, probs, labels = torch.Tensor.numpy(features_mat), torch.Tensor.numpy(probs_mat), torch.Tensor.numpy(labels_mat)\n",
    "\n",
    "np.save('./train/CIFAR10_ResNet18_ce_pretrain_features_train.npy', features)\n",
    "np.save('./train/CIFAR10_ResNet18_ce_pretrain_probs_train.npy', probs)\n",
    "np.save('./train/CIFAR10_ResNet18_ce_pretrain_labels_train.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### test dataset feature, logits, and pics ##########\n",
    "\n",
    "model.eval()\n",
    "new_model.eval()\n",
    "\n",
    "logits_mat = torch.empty((len(test_dataset), 10))\n",
    "features_mat = torch.empty((len(test_dataset), 512))\n",
    "labels_mat = torch.empty((len(test_dataset), 1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        x, y = test_dataset[i]\n",
    "        x = x.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        logits = model(x)\n",
    "        logits_mat[i] = logits.squeeze(0)\n",
    "\n",
    "        features = new_model(x)\n",
    "        features_mat[i] = features.squeeze(0)\n",
    "\n",
    "        labels_mat[i] = y\n",
    "\n",
    "probs_mat = softmax(logits_mat, dim=1)\n",
    "features, probs, labels = torch.Tensor.numpy(features_mat), torch.Tensor.numpy(probs_mat), torch.Tensor.numpy(labels_mat)\n",
    "\n",
    "np.save('./test/CIFAR10_ResNet18_ce_pretrain_features_test.npy', features)\n",
    "np.save('./test/CIFAR10_ResNet18_ce_pretrain_probs_test.npy', probs)\n",
    "np.save('./test/CIFAR10_ResNet18_ce_pretrain_labels_test.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DTD dataset feature, logits, and pics ##########\n",
    "\n",
    "model.eval()\n",
    "new_model.eval()\n",
    "\n",
    "logits_mat = torch.empty((len(DTD_dataset), 10))\n",
    "features_mat = torch.empty((len(DTD_dataset), 512))\n",
    "labels_mat = torch.empty((len(DTD_dataset), 1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(DTD_dataset)):\n",
    "        x, y = DTD_dataset[i]\n",
    "        x = x.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        logits = model(x)\n",
    "        logits_mat[i] = logits.squeeze(0)\n",
    "\n",
    "        features = new_model(x)\n",
    "        features_mat[i] = features.squeeze(0)\n",
    "\n",
    "        labels_mat[i] = y\n",
    "\n",
    "probs_mat = softmax(logits_mat, dim=1)\n",
    "features, probs, labels = torch.Tensor.numpy(features_mat), torch.Tensor.numpy(probs_mat), torch.Tensor.numpy(labels_mat)\n",
    "\n",
    "np.save('./DTD/CIFAR10_ResNet18_ce_pretrain_features_DTD.npy', features)\n",
    "np.save('./DTD/CIFAR10_ResNet18_ce_pretrain_probs_DTD.npy', probs)\n",
    "np.save('./DTD/CIFAR10_ResNet18_ce_pretrain_labels_DTD.npy', labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87fdd5194604a347e8f388098ad93e07421d2acf063829bd614b1fca6dae2dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
